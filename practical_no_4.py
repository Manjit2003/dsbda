# -*- coding: utf-8 -*-
"""Practical no. 4

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q1jOH7gcD0maXBwBmL76evkQ1tM7kLLg
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
# %matplotlib inline
dataset = pd.read_csv("/content/HousingData.csv")
dataset.keys()

dataset.head()
dataset.describe()
dataset.info()
dataset.isnull().sum()

dataset = dataset.fillna(dataset.mean())
dataset.isnull().sum()

# Plot the distribution of 'MEDV' ==> median value of owner-occupied homes in thousands of dollars
sns.set(rc={'figure.figsize':(11.7,8.27)})
sns.displot(dataset['MEDV'],bins=30);
plt.show()

# Compute the correlation matrix
correlation_matrix = dataset.corr().round(2)
# Set the figure size for seaborn plots
plt.figure(figsize=(12, 8))
# Create a heatmap
sns.heatmap(data=correlation_matrix, annot=True)
# Show the plot
plt.show()

plt.figure(figsize=(20, 5))
# Define the features and the target variable
features = ['LSTAT', 'RM']
target = dataset['MEDV']
# Loop through each feature
for i, col in enumerate(features):
 # Create subplots
 plt.subplot(1, len(features), i + 1)

 # Define x and y values for the scatter plot
 x = dataset[col]
 y = target

 # Plot the scatter plot
 plt.scatter(x, y, marker='o')

 # Set title, xlabel, and ylabel for the subplot
 plt.title(col)
 plt.xlabel(col)
 plt.ylabel('MEDV')
plt.show()

# Preparing the data for training the model
import numpy as np
# Combine 'LSTAT' and 'RM' columns into a DataFrame
x = pd.DataFrame(np.c_[dataset['LSTAT'], dataset['RM']], columns=['LSTAT', 'RM'])
# Assign the 'Price' column to the target variable y
y = dataset['MEDV']

from sklearn.model_selection import train_test_split
# Splitting the dataset into training and testing sets
# x contains the features and y contains the target variable
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=5)
# Assigning the training and testing sets to x_train, x_test, y_train, and y_test
# Printing the shapes of the training and testing sets
# The shape represents the number of samples (rows) and features (columns) in each set
print("Training set shapes:")
print("x_train:", x_train.shape)
print("y_train:", y_train.shape)
print("Testing set shapes:")
print("x_test:", x_test.shape)
print("y_test:", y_test.shape)

from sklearn.linear_model import LinearRegression
model=LinearRegression()
# fitting the linear regression model to the training data
model.fit(x_train,y_train)

from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
import numpy as np
# Making predictions on the testing set
y_pred = model.predict(x_test)
# Calculating Root Mean Squared Error (RMSE)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
# Calculating R-squared score
r2 = r2_score(y_test, y_pred)
# Printing model performance metrics for the testing set
print("Model performance for testing set")
print("---------------------------------")
print('RMSE is {}'.format(rmse))
print('R2 score is {}'.format(r2))

# Predicting selling price
# sample_data contains the features for which we want to predict the selling price
sample_data = [[6.89, 9.939]]
# Predicting the selling price using the trained model
price = model.predict(sample_data)
print("Predicted selling price for house: ${:,.2f}".format(price[0]))

import pandas as pd
# Create a DataFrame with sample data and feature names
sample_data_df = pd.DataFrame(sample_data, columns=['LSTAT', 'RM'])
# Predicting the selling price using the trained model
price = model.predict(sample_data_df)
# Printing the predicted selling price
print("Predicted selling price for house: ${:,.2f}".format(price[0]))